import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model, Sequential
import matplotlib.pyplot as plt

data = pd.read_csv('path/API_Calls_Sequence_old.csv')

# Extract sequences and labels
sequences = data['API_Sequence'].tolist()
labels = data['label'].tolist()

# Tokenize and pad sequences
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(sequences)
sequences = tokenizer.texts_to_sequences(sequences)
padded_sequences = pad_sequences(sequences, maxlen=1000)  # Adjust maxlen based on your data

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)

# Define the Stacked Autoencoder
input_dim = X_train.shape[1]  
input_layer = Input(shape=(input_dim,))
encoder = Dense(512, activation='relu')(input_layer)
encoder = Dense(256, activation='relu')(encoder)
encoder = Dense(128, activation='relu')(encoder)
decoder = Dense(256, activation='relu')(encoder)
decoder = Dense(512, activation='relu')(decoder)
decoder = Dense(input_dim, activation='sigmoid')(decoder)
autoencoder = Model(inputs=input_layer, outputs=decoder)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the Autoencoder
autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, validation_split=0.2, shuffle=True)

# Extract features
encoder_model = Model(inputs=input_layer, outputs=encoder)
X_train_encoded = encoder_model.predict(X_train)
X_test_encoded = encoder_model.predict(X_test)

# Define the classifier
classifier = Sequential([
    Dense(64, activation='relu', input_shape=(128,)),  # Input shape matches the encoded feature size
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile the classifier
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the classifier
history = classifier.fit(X_train_encoded, y_train, epochs=20, batch_size=32, validation_data=(X_test_encoded, y_test))

# Evaluate the model
loss, accuracy = classifier.evaluate(X_test_encoded, y_test)
print(f'Accuracy: {accuracy * 100:.2f}%')

# Plot training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0, 1])
plt.legend(loc='upper right')
plt.show()

# Save the classifier model
classifier.save('malware_detection_classifier.h5')
